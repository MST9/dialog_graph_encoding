{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd50dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohit/opt/anaconda3/envs/exp_pytorch_only/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "# from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f21a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8deacad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99bd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', truncation = True, do_lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e842db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue1 = {\"label\": [\"Ketoconazole\"], \"disease\": [\"Dermatitis\"], \"dialog\": [\"Patient: There are small flesh-colored bumps on the finger joints, which are very itchy\", \"Doctor: Hello , How long has this been the case?\", \"Doctor: Did it grow last year?\", \"Doctor: Do you have both hands?\", \"Doctor: It may be tinea pedis or eczema\", \"Patient: It's been a few days, There is only one hand, at first only the index finger, now there are four fingers\", \"patient: what medicine?\", \"doctor: if there is only one hand, the possibility of tinea pedis is high, because eczema is generally symmetrical and long\", \" Doctor: It is recommended to spray locally [MASK]\"], \"original_dialog\": [\"Patient: There are small flesh-colored bumps on the finger joints, which are very itchy\", \"Doctor: Hello, how long has this been happening?\", \"Doctor : Have you grown in the past year?\", \"Doctor: Do you have both hands?\", \"Doctor: It may be tinea pedis or eczema\", \"Patient: It's been a few days and I only have one hand. At first I only had the index finger. Now All four fingers have\", \"Patient: What medicine to use?\", \"Doctor: If there is only one, it is very likely to consider tinea pedis, because eczema is generally symmetrical and long\", \"Doctor: It is recommended to spray locally [MASK]\"] }\n",
    "dialogue2 = {\"label\": [\"mometasone furoate\", \"clarithromycin\", \"pudilan anti-inflammatory oral liquid\", \"licorice tablet\"], \"disease\": [\"rhinitis\"], \"dialog\": [\"patient : Can Xanthium rhinitis capsule be taken with Lanqin Oral Liquid?\", \"Doctor: Hello, do you feel any discomfort?\", \"Doctor: Congestion, runny nose and sore throat?\", \"Patient: stuffy nose and booger Physiological seawater can wash out the very sticky white mucus\", \"Patient: Itchy throat\", \"Patient: Slight cough\", \"Patient: Sinusitis\", \"Doctor: What medication did you use and how did it work\", \" Doctor: How long has this been the case?\", \"Doctor: Is the runny nose running down the throat?\", \"Patient: No backflow rhinitis has affected sleep for many years recently\", \"Patient: I used to take cephalosporin\", \"Patient: It can be relieved by taking it or not. Relapse slowly\", \"Doctor: Do you have sinusitis after sinus CT scan?\", \"Doctor: For the safety of your medication, do you have a history of drug allergies? Do you have poor liver and kidney function?\", \"Patient: Yes\", \"Patient: Sinusitis\", \"Patient: No allergies\", \"Patient: Normal liver and kidneys\", \"Patient: Only one of the two nostrils can pass through\", \"Patient: The pillow should be raised to the point of ventilation\", \" Doctor: According to your description, chronic sinusitis and chronic pharyngitis are likely to be considered. [MASK], [MASK], [MASK], [MASK]\"], \"original_dialog\": [\"Patient: Xanthium rhinitis capsule Can I take it with Lanqin Oral Liquid?\", \"Doctor: Hello, what's wrong with you?\", \"Doctor: Congestion, runny nose and sore throat?\", \"Patient: Congestion and excrement can be washed out by physiological seawater. Sticky white nasal discharge\", \"Patient: Itchy throat\", \"Patient: Cough a little\", \"Patient: Sinusitis\", \"Doctor: What medication has been used and how is it working\", \"Doctor: How long has this been happening? \", \"Doctor: Does the nasal discharge run down the throat?\", \"Patient: I have been suffering from rhinitis for many years, which affects my sleep recently\", \"Patient: I used to take cephalosporin\", \"Patient: It will be relieved after taking it, but it will relapse slowly\", \" Doctor: Have you ever had a sinus CT scan and have sinusitis?\", \"Doctor: For the safety of your medication, do you have a history of drug allergies? Do you have poor liver and kidney function?\", \"Patient: Yes\", \"Patient: Sinusitis\", \"Patient: No allergies\", \"Patient: Normal liver and kidneys\", \"Patient: Only one of the two nostrils can pass through\", \"Patient: Pillow should be raised to ventilate\", \"Doctor: According to your description Considering the possibility of chronic sinusitis and chronic pharyngitis, you can consider [MASK], [MASK], [MASK], [MASK]\"]}\n",
    "dialogue3 = {\"label\": [\"calamine lotion\", \"loratadine\", \"cetirizine\", \"glycyrrhizin\"], \"disease\": [\"dermatitis\"], \"dialog\": [ \"Patient: I have itchy red bumps all over my body, what should I do?\", \"Doctor: Hello, this is an allergy. How long has it been?\", \"Patient: Hello for three days\", \"Doctor: Before the rash , Have you eaten anything special?\", \"Patient: The chest and back are particularly heavy, and there are also on the legs\", \"Doctor: Have you taken any anti-allergic medicine?\", \"Patient: I have taken tuberculosis medicine, and the later cause Abnormal liver function, liver protection treatment for 5 days\", \"Doctor: How many days have you taken the tuberculosis medicine?\", \"Patient: Yiganling Capsule, Glucuronolide Tablet, Muyue Enzyme QIO Capsule and these medicines\", \"Doctor: How many days have you taken good tuberculosis medicine?\", \"Patient: For four months, the doctor asked to stop the liver function test first, and the liver function test of aspartate transanase 184. Let's stop the liver protection treatment, these few days I have a skin rash all over my body, what kind of medicine should I use? Thank you\", \"Doctor: Well, there is a high possibility of allergy to these hepatoprotective drugs\", \"Doctor: You can take [MASK, [MASK], [MASK] [MASK] orally. [MASK]\"], \"original_dialog\": [\"Patient: I have itchy red bumps all over my body, what should I do?\", \"Doctor: Hello, how long have you been allergic to?\", \"Patient: Hello It's been three days\", \"Doctor: Before the rash, did you take anything special?\", \"Patient: The chest and back are very large, and there are also on the legs\", \"Doctor: Have you taken any anti-allergic medicine?\" , \"Patient: Taking tuberculosis medicine, and then discontinued due to abnormal liver function, liver protection treatment for five days\", \"Doctor: How long did you take tuberculosis medicine?\", \"Patient: Yiganling capsule, glucurolactone tablet, Murayuki enzyme QIO capsules and these medicines\", \"Doctor: How many days have you taken good tuberculosis medicine?\", \"Patient: For four months, the doctor asked to stop the liver function test first, and the liver function test of aspartate transanase 184 .Let me stop the liver-protective treatment. I have a rash all over the body these days. What kind of medicine should I use? Thank you.\", \"Doctor: Okay, that is, there is a high possibility of allergy to these liver-protective drugs.\", \"Doctor: You can take [MASK, [MASK][MASK]Use [MASK]\"]}\n",
    "dialogue4 = {\"label\": [\"Chuanbei Loquat Dew\"], \"disease\": [\"Upper respiratory tract infection\"], \"dialog\": [\"Patient: breastfeeding cough, sore throat, always want to spit, has taken three The sky is not getting better, what kind of medicine can I take?\", \"Doctor: Hello, you can use some sense of the four seasons or [MASK]\"], \"original_dialog\": [\"Patient: breastfeeding cough, sore throat, always I want to spit, but I have been taking Pudilan for three days and it has not improved, what kind of medicine can I take?\", \"Doctor: Hello, you can use some sense of the four seasons or [MASK]\"]}\n",
    "dialogue5 = {\"label\": [\"erythromycin\", \"eucalyptus, lime and pinene enteric-coated soft capsules\", \"mometasone furoate\", \"cephalosporins\"], \"disease\": [\"rhinitis\"], \"dialog\": [ \"Patient: The rhinitis is on, the left nasal cavity is sore and painful, and the condition is more serious at night. What kind of medicine can I take orally\", \"Doctor: Hello, how long have you been in this situation?\", \"Patient: I had a cold a few days ago, which caused it, It's been two days\", \"Doctor: Is there any obvious nasal congestion, purulent nasal discharge?\", \"Patient: There is a lot of nasal discharge, nasal congestion, not purulent snot, transparent sticky snot. A little cold, no fever, left nasal cavity Soreness and pain\", \"Doctor: Have you ever had sinusitis before?\", \"Patient: Yes, it happens every year\", \"Doctor: It's a sinusitis in your case. Haven't been to Wuhan or been in contact with it. Someone from Wuhan, right?\", \"Patient: No no\", \"Patient: All at home?\", \"Patient: I have budesonide at home, what medicine can I take\", \"Doctor: If the pain is not particularly severe If so, you can take it orally first, [MASK], [MASK], [MASK], [MASK]\"], \"original_dialog\": [\"Patient: rhinitis attack, left nasal cavity soreness and pain, if it is more serious at night, you can take it orally What kind of medicine?\", \"Doctor: Hello, how long has this been the case?\", \"Patient: I have a cold a few days ago, which caused it, and it has been two days\", \"Doctor: Is there any obvious nasal congestion and runny nose? \", \"Patient: Lots of snot, stuffy nose, not purulent snot, transparent viscous snot. A little cold, no fever, sore and painful left nasal cavity\", \"Doctor: Have you ever had sinusitis before?\", \"Patient: Yes, it happens every year\", \"Doctor: In your case, consider a sinusitis attack. Have you ever been to Wuhan or been in contact with people from Wuhan?\", \"Patient: No no\", \"Patient: All are there. At home?\", \"Patient: I have budesonide at home, what other medicines can I take\", \"Doctor: If the pain is not particularly severe, you can take [MASK], [MASK], [MASK], [MASK] orally first. ], [MASK]\"]}\n",
    "\n",
    "dialog = [dialogue1, dialogue2, dialogue3, dialogue4, dialogue5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e79262",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "  \"berberine\": 0,\n",
    "  \"Trimebutine\": 1,\n",
    "  \"Probiotics\": 2,\n",
    "  \"crack\": 3,\n",
    "  \"dexamethasone\": 4,\n",
    "  \"Ebastine\": 5,\n",
    "  \"budesonide\": 6,\n",
    "  \"amoxicillin\": 7,\n",
    "  \"mometasone furoate\": 8,\n",
    "  \"Fenghanmao Granules\": 9,\n",
    "  \"omeprazole\": 10,\n",
    "  \"Compound Digestive Enzymes\": 11,\n",
    "  \"Mosapride\": 12,\n",
    "  \"Aluminum-magnesium compound\": 13,\n",
    "  \"Pudilan Anti-inflammatory Oral Liquid\": 14,\n",
    "  \"Chuanbei Loquat Dew\": 15,\n",
    "  \"erythromycin\": 16,\n",
    "  \"Compound methoxyphenamine capsules\": 17,\n",
    "  \"montelukast\": 18,\n",
    "  \"Cold Spirit\": 19,\n",
    "  \"Entecavir\": 20,\n",
    "  \"glutathione\": 21,\n",
    "  \"Su Huang Zhike Capsules\": 22,\n",
    "#   \"Eucalyptus, Lime and Pinene Enteric Soft Capsules\": 23, (Original)\n",
    "  \"Eucalyptus, Lime and Pinene Enteric-Coated Soft Capsules\": 23,\n",
    "  \"Calamine Lotion\": 24,\n",
    "  \"Tongqiao rhinitis granules\": 25,\n",
    "  \"Lianhua Qingwen Capsule\": 26,\n",
    "  \"oseltamivir\": 27,\n",
    "  \"dextromethorphan\": 28,\n",
    "  \"loratadine\": 29,\n",
    "  \"Mesalazine\": 30,\n",
    "  \"Tylenol\": 31,\n",
    "  \"Silymarin\": 32,\n",
    "  \"Polyene phosphatidylcholine\": 33,\n",
    "  \"Physiological Sodium Chloride Solution\": 34,\n",
    "  \"Montmorillonite\": 35,\n",
    "#     \"Licorice Tablets\": 36, (Original)\n",
    "  \"Licorice Tablet\": 36,\n",
    "  \"minocycline\": 37,\n",
    "  \"Sanjiuweitai\": 38,\n",
    "  \"Hydrocortisone\": 39,\n",
    "  \"Colloidal Bismuth Pectin\": 40,\n",
    "  \"Glutamine\": 41,\n",
    "  \"azithromycin\": 42,\n",
    "  \"cephalosporins\": 43,\n",
    "  \"adapalene\": 44,\n",
    "  \"Ambroxol\": 45,\n",
    "  \"tacrolimus\": 46,\n",
    "  \"glycyrrhizin\": 47,\n",
    "  \"Chang Yanning\": 48,\n",
    "  \"levofloxacin\": 49,\n",
    "  \"Panlangen\": 50,\n",
    "  \"acetaminophen\": 51,\n",
    "  \"cetirizine\": 52,\n",
    "  \"Triamcinolone acetonide\": 53,\n",
    "  \"Jianwei Xiaoshi Tablets\": 54,\n",
    "  \"aciclovir\": 55,\n",
    "  \"Ketoconazole\": 56,\n",
    "  \"Anisodamine\": 57,\n",
    "  \"ibuprofen\": 58,\n",
    "  \"clarithromycin\": 59,\n",
    "  \"Tenofovir\": 60,\n",
    "  \"Metoclopramide\": 61,\n",
    "  \"Hathinad\": 62,\n",
    "  \"Sulphur soap\": 63,\n",
    "  \"Shuanghuanglian Oral Liquid\": 64,\n",
    "  \"antiviral particles\": 65,\n",
    "  \"Bicyclic alcohol\": 66,\n",
    "  \"New Healing Fluid\": 67,\n",
    "  \"Selenium Disulfide\": 68,\n",
    "  \"Fuzheng Huayu Capsule\": 69\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422c7a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'berberine': 0, 'trimebutine': 1, 'probiotics': 2, 'crack': 3, 'dexamethasone': 4, 'ebastine': 5, 'budesonide': 6, 'amoxicillin': 7, 'mometasone furoate': 8, 'fenghanmao granules': 9, 'omeprazole': 10, 'compound digestive enzymes': 11, 'mosapride': 12, 'aluminum-magnesium compound': 13, 'pudilan anti-inflammatory oral liquid': 14, 'chuanbei loquat dew': 15, 'erythromycin': 16, 'compound methoxyphenamine capsules': 17, 'montelukast': 18, 'cold spirit': 19, 'entecavir': 20, 'glutathione': 21, 'su huang zhike capsules': 22, 'eucalyptus, lime and pinene enteric-coated soft capsules': 23, 'calamine lotion': 24, 'tongqiao rhinitis granules': 25, 'lianhua qingwen capsule': 26, 'oseltamivir': 27, 'dextromethorphan': 28, 'loratadine': 29, 'mesalazine': 30, 'tylenol': 31, 'silymarin': 32, 'polyene phosphatidylcholine': 33, 'physiological sodium chloride solution': 34, 'montmorillonite': 35, 'licorice tablet': 36, 'minocycline': 37, 'sanjiuweitai': 38, 'hydrocortisone': 39, 'colloidal bismuth pectin': 40, 'glutamine': 41, 'azithromycin': 42, 'cephalosporins': 43, 'adapalene': 44, 'ambroxol': 45, 'tacrolimus': 46, 'glycyrrhizin': 47, 'chang yanning': 48, 'levofloxacin': 49, 'panlangen': 50, 'acetaminophen': 51, 'cetirizine': 52, 'triamcinolone acetonide': 53, 'jianwei xiaoshi tablets': 54, 'aciclovir': 55, 'ketoconazole': 56, 'anisodamine': 57, 'ibuprofen': 58, 'clarithromycin': 59, 'tenofovir': 60, 'metoclopramide': 61, 'hathinad': 62, 'sulphur soap': 63, 'shuanghuanglian oral liquid': 64, 'antiviral particles': 65, 'bicyclic alcohol': 66, 'new healing fluid': 67, 'selenium disulfide': 68, 'fuzheng huayu capsule': 69}\n"
     ]
    }
   ],
   "source": [
    "lower_case_label_dict = {}\n",
    "\n",
    "for d in label_dict:\n",
    "#     print(d,' ',label_dict[d])\n",
    "    d_lower = d.lower()\n",
    "    lower_case_label_dict [d_lower] = label_dict[d]\n",
    "    \n",
    "print(lower_case_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6acb1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400ad1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670f3160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = {\n",
    "        'additional_special_tokens' : ['[DOC]', '[PAT]']\n",
    "    }\n",
    "\n",
    "tokenizer.add_special_tokens(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e25b47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[DOC]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7daaacd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30523"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[PAT]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61732cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30524"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb9d773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30524, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb51e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 102, 0, 101, 103, 30522, 30523]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950119a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]', '[DOC]', '[PAT]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ccd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement(dlog):\n",
    "    dialog_list = []\n",
    "    whos_turn = []\n",
    "    \n",
    "    for d in dlog:\n",
    "        dialog = d.lower()\n",
    "        idx_pat = re.search('patient', dialog)\n",
    "        idx_doc = re.search('doctor', dialog)\n",
    "        \n",
    "        if(idx_pat):\n",
    "            z = re.sub('patient', '[PAT]', dialog)\n",
    "            whos_turn.append('p')\n",
    "        \n",
    "        else:\n",
    "            z = re.sub('doctor', '[DOC]', dialog)\n",
    "            whos_turn.append('d')\n",
    "        \n",
    "        dialog_list.append(z)\n",
    "   \n",
    "    return dialog_list, whos_turn     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb50de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_block(whos_turn):\n",
    "    block = {}\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(len(whos_turn)):\n",
    "        if i==0:\n",
    "            block[i]=cnt\n",
    "        elif whos_turn[i] == whos_turn[i-1]:\n",
    "             block[i]=cnt\n",
    "        elif whos_turn[i] != whos_turn[i-1]:\n",
    "                   block[i] = cnt+1\n",
    "                   cnt = cnt+1\n",
    "                   \n",
    "    return block               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8911142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edges(whos_turn, block):\n",
    "    edge_list = []\n",
    "    \n",
    "    for i in range(len(whos_turn)):\n",
    "        for j in range(i+1, len(whos_turn)):\n",
    "            if((block[i] == block[j]) or block[i] + 1 == block[j]):\n",
    "                edge_1 = [i,j]\n",
    "                edge_2 = [j,i]\n",
    "                edge_list.append(edge_1)\n",
    "                edge_list.append(edge_2)\n",
    "    \n",
    "    edge_list = torch.tensor(edge_list, dtype = torch.long)\n",
    "    edge_list = edge_list.T\n",
    "    \n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68ffb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_list_generate(labels):\n",
    "    labels_list = []\n",
    "# labels = [1,2,3]\n",
    "# 0 0\n",
    "# 1 0\n",
    "# 1 1\n",
    "# 0 1\n",
    "# labels_one_hot = [0,1,1,1,rest_zero]\n",
    "#     one_hot_label_list = []\n",
    "\n",
    "#     for i in range(70):\n",
    "#         one_hot_label_list.append(0)\n",
    "# #     print(one_hot_label_list)\n",
    "    \n",
    "#     one_hot_label_list = torch.Tensor(one_hot_label_list)\n",
    "    one_hot_label_list = torch.zeros(1,70)\n",
    "\n",
    "    for label in labels:\n",
    "        label_lower = label.lower()\n",
    "#         print(label_lower)\n",
    "#         print(lower_case_label_dict[label_lower])\n",
    "        number = lower_case_label_dict[label_lower]\n",
    "        one_hot_label_list[0][number] = 1\n",
    "#         print(one_hot_label_list)\n",
    "#         print('error above')\n",
    "#         labels_list.append(lower_case_label_dict[label_lower])\n",
    "    \n",
    "#     labels_list = torch.Tensor(labels_list)\n",
    "#     print(one_hot_label_list.shape)\n",
    "#     torch.reshape(one_hot_label_list, (1,-1))\n",
    "    print(one_hot_label_list.shape)\n",
    "    return one_hot_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "790c7aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([1, 70])\n",
      "torch.int64\n",
      "torch.Size([1, 70])\n",
      "torch.int64\n",
      "torch.Size([1, 70])\n",
      "torch.int64\n",
      "torch.Size([1, 70])\n",
      "torch.int64\n",
      "torch.Size([1, 70])\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for dg in dialog:\n",
    "    dlog = dg['dialog']\n",
    "    \n",
    "    dlog_list, whos_turn = replacement(dlog)\n",
    "    \n",
    "    encoding_dlog = tokenizer(dlog_list, return_tensors = 'pt', padding = True)\n",
    "    \n",
    "    output_encoding = bert_model(**encoding_dlog)\n",
    "    \n",
    "    utterance_encoding = output_encoding['last_hidden_state'].permute(1,0,2)[0]\n",
    "    \n",
    "    block = find_block(whos_turn)\n",
    "    \n",
    "    edge_list = make_edges(whos_turn, block)\n",
    "    print(edge_list.dtype)\n",
    "    edge_weights = torch.tensor([1] * edge_list.shape[1], dtype = torch.float32)\n",
    "    \n",
    "    label_dlog = dg['label']\n",
    "    \n",
    "    one_hot_label_list = labels_list_generate(label_dlog)\n",
    "    \n",
    "    data_train = Data(x = utterance_encoding, edge_index = edge_list, edge_attr = edge_weights, y = one_hot_label_list)\n",
    "    \n",
    "    data_list.append(data_train)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63c6e7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[9, 768], edge_index=[2, 48], edge_attr=[48], y=[1, 70]),\n",
       " Data(x=[22, 768], edge_index=[2, 168], edge_attr=[168], y=[1, 70]),\n",
       " Data(x=[13, 768], edge_index=[2, 26], edge_attr=[26], y=[1, 70]),\n",
       " Data(x=[2, 768], edge_index=[2, 2], edge_attr=[2], y=[1, 70]),\n",
       " Data(x=[12, 768], edge_index=[2, 32], edge_attr=[32], y=[1, 70])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1413a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    def process(self):\n",
    "#         # Read data into huge `Data` list.\n",
    "        data_list1 = data_list\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list1 = [data for data in data_list1 if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list1 = [self.pre_transform(data) for data in data_list1]\n",
    "\n",
    "        data, slices = self.collate(data_list1)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c111b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyOwnDataset(root=\"my_own_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da10c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyOwnDataset(5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_own = MyOwnDataset(root=\"my_own_dataset/\")\n",
    "my_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "442644b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_own[0].num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc348351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_own.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08d5e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_own[0].num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcd4ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aefc45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohit/opt/anaconda3/envs/exp_pytorch_only/lib/python3.7/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x7f8a42afbf90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(data_list, batch_size=2)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74709fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1\n",
      "\n",
      "Number of graphs in current batch :  2\n",
      "DataBatch(x=[31, 768], edge_index=[2, 216], edge_attr=[216], y=[2, 70], batch=[31], ptr=[3])\n",
      "Number of classes shape :  torch.Size([2, 70])\n",
      "\n",
      "\n",
      "Step:  2\n",
      "\n",
      "Number of graphs in current batch :  2\n",
      "DataBatch(x=[15, 768], edge_index=[2, 28], edge_attr=[28], y=[2, 70], batch=[15], ptr=[3])\n",
      "Number of classes shape :  torch.Size([2, 70])\n",
      "\n",
      "\n",
      "Step:  3\n",
      "\n",
      "Number of graphs in current batch :  1\n",
      "DataBatch(x=[12, 768], edge_index=[2, 32], edge_attr=[32], y=[1, 70], batch=[12], ptr=[2])\n",
      "Number of classes shape :  torch.Size([1, 70])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    print('Step: ', step + 1)\n",
    "    print()\n",
    "    print('Number of graphs in current batch : ', data.num_graphs)\n",
    "    print(data)\n",
    "    print('Number of classes shape : ',data.y.shape)\n",
    "#     print('Number of classes : ',data.y)\n",
    "#     print('Data batch : ', data.batch.shape[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7295fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args):\n",
    "        super(GAT,self).__init__()\n",
    "        \n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=args['heads'])\n",
    "        self.conv2 = GATConv(hidden_dim*args['heads'], hidden_dim, heads = args['heads'])\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim*args['heads'], output_dim)\n",
    "        \n",
    "    def forward(self, data, batch):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x=self.conv1(x, edge_index)\n",
    "        x=F.dropout(F.relu(x), p=args['dropout'], training=self.training)\n",
    "        \n",
    "        x=self.conv2(x, edge_index)\n",
    "        \n",
    "        \n",
    "        x=global_mean_pool(x, batch)\n",
    "        \n",
    "        x=F.dropout(F.relu(x), p=args['dropout'], training=self.training)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "#         x = x.view(-1)\n",
    "#         x = torch.nn.Sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd23a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class GAT(torch.nn.Module):\n",
    "#     def __init__(self,input_dim, hidden_dim, output_dim,args):\n",
    "#         super(GAT, self).__init__()\n",
    "#         #use our gat message passing \n",
    "#         self.conv1 = GATConv(input_dim, hidden_dim, heads=args['heads'])\n",
    "#         self.conv2 = GATConv(args['heads'] * hidden_dim, hidden_dim, heads=args['heads'])\n",
    "        \n",
    "#         self.post_mp = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(args['heads'] * hidden_dim, hidden_dim), torch.nn.Dropout(args['dropout'] ), \n",
    "#             torch.nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "#     def forward(self, data, batch):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         # Layer 1\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.dropout(F.relu(x), p=args['dropout'], training=self.training)\n",
    "#         # Layer 2\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = F.dropout(F.relu(x), p=args['dropout'], training=self.training)\n",
    "#         # MLP output\n",
    "#         x = self.post_mp(x)\n",
    "        \n",
    "#         x=global_mean_pool(x, batch)\n",
    "        \n",
    "#         return F.sigmoid(x)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58dd28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "      'heads':2,\n",
    "      'dropout': 0.5\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2d2e526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (conv1): GATConv(768, 64, heads=2)\n",
       "  (conv2): GATConv(128, 64, heads=2)\n",
       "  (lin): Linear(in_features=128, out_features=70, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAT(input_dim = 768, hidden_dim = 64, output_dim = 70, args = args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32874940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (conv1): GATConv(768, 64, heads=2)\n",
       "  (conv2): GATConv(128, 64, heads=2)\n",
       "  (lin): Linear(in_features=128, out_features=70, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a294a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "445b8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = train_loader.to(device)\n",
    "# for data in train_loader:\n",
    "#     print(data)\n",
    "#     data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20fbe3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print('Batch size : ',data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7d16f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "#     hidden = model.init_hidden(140)\n",
    "    \n",
    "    for data in train_loader:\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "# #         output = model(x)\n",
    "#         output = model(data, data.batch)\n",
    "#         print('output shape : ', output.shape)\n",
    "#         print('output : ',output)\n",
    "# #         loss = criterion(output, y)\n",
    "#         loss = criterion(output, data.y)\n",
    "#         loss.backward(retain_graph=True)\n",
    "# #         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print('Loss: {:.3f}'.format(loss.item()))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         hidden = repackage_hidden(hidden)\n",
    "           \n",
    "        optimizer.zero_grad()\n",
    "#         print(data.batch)\n",
    "        out = model(data, data.batch)\n",
    "#         out = torch.randn(data.num_graphs, 70)\n",
    "        print('Prediction : ', out)\n",
    "        print('Prediction shape : ', out.shape)\n",
    "        print('Ground Truth Shape : ',data.y.shape)\n",
    "        print('Ground Truth : ',data.y)\n",
    "        \n",
    "        loss = criterion(out, data.y)\n",
    "        print('loss : ',loss)\n",
    "#         loss.requires_grad = True\n",
    "        loss.backward(retain_graph=True) \n",
    "        \n",
    "        \n",
    "#         loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a239a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "# #     criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     out = model(data, data.batch)\n",
    "#     loss = criterion(out, data.y.to(torch.float))\n",
    "#     loss.backward(retain_graph=True)\n",
    "#     optimizer.step()\n",
    "\n",
    "#     return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbbec175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(loader):\n",
    "#     model.eval()\n",
    "    \n",
    "#     correct = 0\n",
    "#     for data in loader:\n",
    "#         out = model(data, data.batch)\n",
    "#         print('Batch length : ', data.batch.shape[0])\n",
    "#         print('Size of output : ', out.shape)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "429123cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number :  1\n",
      "Prediction :  tensor([[0.5140, 0.4651, 0.4673, 0.4803, 0.5188, 0.4743, 0.4722, 0.4560, 0.4802,\n",
      "         0.5712, 0.4709, 0.5455, 0.4157, 0.5079, 0.5212, 0.4914, 0.5004, 0.5322,\n",
      "         0.4877, 0.3956, 0.4137, 0.4929, 0.4049, 0.5735, 0.5077, 0.5134, 0.4738,\n",
      "         0.5134, 0.4516, 0.5330, 0.4874, 0.4877, 0.5069, 0.4485, 0.4816, 0.5004,\n",
      "         0.4554, 0.4197, 0.4550, 0.5122, 0.4735, 0.4893, 0.4958, 0.4690, 0.5002,\n",
      "         0.5700, 0.4223, 0.5011, 0.4649, 0.5817, 0.5440, 0.4450, 0.3826, 0.3820,\n",
      "         0.5485, 0.5041, 0.5037, 0.4179, 0.4872, 0.5684, 0.4571, 0.4680, 0.4574,\n",
      "         0.4601, 0.4815, 0.4826, 0.4473, 0.5235, 0.5274, 0.4849],\n",
      "        [0.5308, 0.5181, 0.4803, 0.4251, 0.4764, 0.4163, 0.5028, 0.4576, 0.4931,\n",
      "         0.5653, 0.5211, 0.5621, 0.3849, 0.5462, 0.5144, 0.5026, 0.5200, 0.5027,\n",
      "         0.5071, 0.3818, 0.4037, 0.5134, 0.4042, 0.4953, 0.5542, 0.4977, 0.5108,\n",
      "         0.4807, 0.4688, 0.4858, 0.5405, 0.5167, 0.4423, 0.5120, 0.4982, 0.5254,\n",
      "         0.4572, 0.3891, 0.4532, 0.5433, 0.5493, 0.4251, 0.4697, 0.4705, 0.4655,\n",
      "         0.5283, 0.4007, 0.5957, 0.5303, 0.5180, 0.4781, 0.4971, 0.4070, 0.3904,\n",
      "         0.4986, 0.5502, 0.5046, 0.4506, 0.5572, 0.5122, 0.4621, 0.4849, 0.4695,\n",
      "         0.4960, 0.4770, 0.5007, 0.5233, 0.4358, 0.4456, 0.4710]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([2, 70])\n",
      "Ground Truth Shape :  torch.Size([2, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.9478, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohit/opt/anaconda3/envs/exp_pytorch_only/lib/python3.7/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  tensor([[0.4805, 0.2536, 0.1962, 0.2109, 0.5300, 0.4745, 0.5942, 0.4498, 0.3167,\n",
      "         0.3801, 0.6701, 0.4815, 0.2883, 0.3833, 0.4002, 0.3539, 0.4637, 0.4861,\n",
      "         0.3130, 0.1316, 0.4364, 0.2712, 0.2048, 0.4562, 0.4169, 0.3009, 0.5450,\n",
      "         0.2747, 0.4019, 0.4221, 0.3515, 0.4104, 0.3915, 0.2605, 0.5989, 0.3294,\n",
      "         0.5510, 0.3003, 0.4086, 0.4045, 0.3312, 0.5750, 0.3883, 0.1246, 0.4986,\n",
      "         0.5658, 0.1929, 0.6749, 0.2615, 0.6207, 0.5497, 0.5370, 0.4058, 0.3813,\n",
      "         0.5040, 0.5187, 0.5393, 0.3945, 0.4391, 0.6494, 0.3841, 0.5056, 0.5003,\n",
      "         0.2215, 0.3705, 0.3645, 0.6091, 0.2102, 0.4688, 0.4319],\n",
      "        [0.1810, 0.1812, 0.0564, 0.3938, 0.1450, 0.2634, 0.1860, 0.5314, 0.3430,\n",
      "         0.4353, 0.3335, 0.3225, 0.0189, 0.3793, 0.2808, 0.0861, 0.6491, 0.1996,\n",
      "         0.5985, 0.0259, 0.0980, 0.2420, 0.1722, 0.1969, 0.5806, 0.2712, 0.4160,\n",
      "         0.0991, 0.2086, 0.5173, 0.2168, 0.3760, 0.2106, 0.1247, 0.3073, 0.1090,\n",
      "         0.3715, 0.0290, 0.0579, 0.3223, 0.6706, 0.5211, 0.2647, 0.2800, 0.2027,\n",
      "         0.4229, 0.1891, 0.1907, 0.2648, 0.6390, 0.5708, 0.4247, 0.2790, 0.0540,\n",
      "         0.4200, 0.4923, 0.8653, 0.1032, 0.2296, 0.8418, 0.2054, 0.2202, 0.0488,\n",
      "         0.0400, 0.1315, 0.4444, 0.3166, 0.1702, 0.0614, 0.1555]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([2, 70])\n",
      "Ground Truth Shape :  torch.Size([2, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.8731, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Prediction :  tensor([[1.5480e-02, 6.5893e-03, 3.7821e-02, 9.3412e-04, 5.3188e-03, 1.4984e-01,\n",
      "         2.2284e-02, 4.2508e-01, 6.2517e-01, 5.0820e-01, 4.0446e-02, 3.0361e-02,\n",
      "         1.6689e-02, 1.6806e-02, 1.2077e-02, 1.0249e-01, 3.3659e-03, 8.6527e-01,\n",
      "         2.6773e-02, 1.1958e-03, 2.9312e-04, 3.8209e-01, 1.1588e-02, 1.7261e-02,\n",
      "         1.5812e-02, 6.2287e-02, 5.2328e-02, 4.4836e-02, 2.6708e-01, 2.4498e-02,\n",
      "         4.7916e-04, 1.0214e-01, 6.5392e-03, 3.2322e-04, 3.7167e-04, 6.7125e-02,\n",
      "         4.2719e-01, 2.0259e-02, 3.6565e-04, 1.4934e-01, 3.4820e-02, 9.3955e-03,\n",
      "         1.0564e-02, 4.0119e-02, 2.7453e-01, 3.3143e-01, 1.6338e-03, 3.7675e-01,\n",
      "         5.7724e-02, 2.1951e-01, 3.5197e-01, 1.1511e-03, 8.4766e-03, 7.5749e-03,\n",
      "         5.3847e-02, 2.9292e-01, 3.4828e-02, 7.6095e-03, 2.8116e-01, 6.6680e-01,\n",
      "         9.9782e-03, 3.2428e-03, 1.7769e-02, 3.0111e-04, 1.2497e-02, 2.8627e-02,\n",
      "         4.5800e-03, 4.7517e-02, 1.9116e-02, 5.1645e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([1, 70])\n",
      "Ground Truth Shape :  torch.Size([1, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.7445, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch number :  2\n",
      "Prediction :  tensor([[1.5734e-04, 9.8184e-05, 2.5652e-04, 1.0494e-06, 8.7035e-06, 1.7399e-04,\n",
      "         1.1046e-03, 1.6566e-04, 3.6949e-01, 2.0563e-01, 2.5816e-04, 1.0268e-03,\n",
      "         2.0183e-05, 6.0120e-06, 9.2005e-04, 3.7680e-04, 1.2334e-03, 2.5291e-02,\n",
      "         2.9533e-04, 4.3877e-08, 3.7980e-08, 5.9415e-06, 2.9800e-06, 1.9877e-03,\n",
      "         1.7071e-03, 1.1133e-05, 5.0185e-04, 1.3198e-04, 1.6656e-05, 6.0263e-03,\n",
      "         6.5932e-06, 4.7836e-04, 8.2622e-06, 5.4773e-05, 2.1722e-07, 2.9800e-04,\n",
      "         4.4815e-05, 2.8192e-07, 1.2975e-07, 4.5250e-03, 8.2189e-04, 4.9331e-05,\n",
      "         7.1787e-06, 6.3206e-04, 3.7840e-03, 4.8605e-02, 5.5138e-06, 3.3729e-02,\n",
      "         1.2083e-03, 5.9179e-02, 6.5900e-02, 2.5555e-05, 1.4669e-05, 7.6130e-07,\n",
      "         8.0838e-05, 3.1677e-02, 2.5405e-03, 1.7951e-05, 5.3142e-04, 1.9951e-04,\n",
      "         5.0316e-06, 2.0828e-05, 7.6202e-08, 4.4857e-03, 4.3913e-04, 3.1905e-05,\n",
      "         4.2586e-06, 4.4941e-05, 6.2318e-05, 1.4629e-03],\n",
      "        [7.7446e-04, 1.1545e-02, 7.1005e-05, 1.7193e-05, 4.0705e-05, 2.7836e-04,\n",
      "         7.7950e-03, 1.2003e-05, 4.7295e-01, 2.4685e-01, 2.9850e-04, 1.4913e-02,\n",
      "         2.0495e-06, 1.1240e-04, 6.6291e-03, 5.1325e-05, 2.3997e-04, 3.6022e-02,\n",
      "         7.2835e-03, 1.3646e-08, 2.5753e-07, 3.7960e-04, 3.4518e-05, 8.9646e-02,\n",
      "         1.8243e-02, 3.4022e-06, 4.3726e-03, 2.7538e-04, 3.0498e-07, 1.5673e-02,\n",
      "         7.6044e-07, 1.3596e-03, 3.6953e-05, 3.9698e-04, 2.1384e-05, 1.5609e-04,\n",
      "         7.1548e-04, 2.1094e-07, 2.7424e-07, 3.4359e-03, 6.6140e-03, 7.4709e-05,\n",
      "         1.3234e-04, 5.6888e-04, 8.6504e-04, 1.8451e-03, 2.5995e-07, 8.6561e-03,\n",
      "         2.2831e-02, 3.7461e-03, 4.5784e-03, 2.0545e-05, 1.6163e-04, 1.7217e-06,\n",
      "         1.1347e-04, 5.9458e-01, 7.0324e-03, 8.6146e-07, 3.6741e-04, 9.1772e-03,\n",
      "         1.8084e-04, 3.5763e-04, 2.0236e-04, 1.6832e-03, 1.4331e-02, 7.3405e-05,\n",
      "         7.1829e-05, 5.4471e-07, 3.0826e-05, 1.3013e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([2, 70])\n",
      "Ground Truth Shape :  torch.Size([2, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.6993, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Prediction :  tensor([[4.2012e-06, 2.2439e-03, 8.5134e-04, 2.9536e-06, 2.7144e-04, 5.2579e-04,\n",
      "         2.4243e-02, 4.3764e-02, 2.0618e-01, 5.9599e-01, 9.1609e-04, 2.2177e-03,\n",
      "         5.8408e-06, 4.2232e-01, 5.1534e-04, 1.5292e-05, 1.8862e-04, 1.1881e-01,\n",
      "         2.6114e-02, 5.9864e-07, 4.7280e-05, 9.6923e-04, 2.4985e-04, 1.8803e-04,\n",
      "         1.0825e-05, 3.5845e-02, 1.8293e-04, 1.2192e-05, 1.1180e-04, 2.4986e-04,\n",
      "         2.5686e-04, 1.7512e-05, 8.5102e-04, 1.5944e-03, 5.0694e-04, 2.5832e-04,\n",
      "         1.0216e-02, 6.3518e-06, 7.0193e-03, 1.7089e-01, 1.7144e-04, 2.3790e-04,\n",
      "         9.0920e-05, 9.9784e-06, 1.1477e-03, 5.6271e-03, 1.8077e-07, 1.1483e-03,\n",
      "         1.3166e-05, 1.8269e-03, 3.7451e-03, 1.0327e-05, 1.1671e-04, 9.7740e-04,\n",
      "         1.0381e-05, 2.7410e-02, 2.2047e-04, 6.3890e-08, 8.1708e-04, 7.5221e-03,\n",
      "         3.0953e-04, 4.4221e-05, 1.4083e-02, 1.6048e-05, 4.6648e-03, 9.7691e-05,\n",
      "         1.7694e-03, 3.4271e-06, 2.1986e-06, 1.4933e-02],\n",
      "        [3.7079e-07, 8.3462e-04, 1.6027e-06, 4.0536e-08, 5.1169e-07, 2.2935e-10,\n",
      "         7.7673e-04, 5.5022e-06, 3.7858e-01, 2.6443e-03, 2.0215e-03, 2.3520e-04,\n",
      "         9.2838e-10, 5.2131e-02, 1.3277e-05, 7.6853e-05, 1.0877e-02, 2.9662e-05,\n",
      "         1.0790e-04, 1.9584e-07, 1.1793e-07, 1.6585e-06, 1.4788e-06, 4.9463e-02,\n",
      "         2.7179e-04, 2.2858e-06, 4.7417e-06, 2.1985e-09, 1.7279e-03, 7.1146e-07,\n",
      "         6.5624e-05, 3.6404e-07, 1.0023e-06, 2.3510e-04, 1.2481e-06, 1.1872e-05,\n",
      "         2.2088e-04, 4.7759e-07, 1.3031e-08, 2.0322e-05, 1.5225e-03, 1.0786e-04,\n",
      "         1.2060e-04, 1.4023e-05, 1.0909e-07, 2.8318e-03, 1.9498e-09, 2.6000e-03,\n",
      "         3.1284e-05, 2.0735e-04, 3.2333e-06, 4.2730e-06, 1.1332e-08, 4.1114e-07,\n",
      "         4.2763e-06, 6.0022e-03, 1.6124e-05, 6.6146e-12, 2.0806e-04, 2.2297e-03,\n",
      "         1.5536e-07, 1.4056e-05, 1.5694e-05, 3.3178e-05, 3.9582e-05, 2.1663e-07,\n",
      "         3.6363e-07, 8.1764e-08, 4.5194e-10, 1.6260e-07]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([2, 70])\n",
      "Ground Truth Shape :  torch.Size([2, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.7020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  tensor([[6.0132e-09, 1.0587e-15, 8.1854e-14, 2.6627e-14, 2.2443e-10, 8.7240e-14,\n",
      "         1.0781e-05, 1.4088e-05, 1.0342e-02, 9.7916e-09, 3.5488e-09, 9.9735e-07,\n",
      "         1.2274e-15, 1.5801e-09, 1.7502e-05, 2.0085e-10, 1.0647e-10, 8.2166e-09,\n",
      "         6.1938e-10, 2.3559e-15, 8.3240e-12, 5.3658e-11, 3.1189e-15, 2.6884e-09,\n",
      "         2.5561e-12, 1.1021e-14, 4.0450e-09, 5.1173e-13, 4.3400e-09, 5.8545e-11,\n",
      "         8.3924e-13, 1.4484e-08, 1.9948e-11, 2.4919e-08, 1.9879e-12, 4.6580e-12,\n",
      "         4.6598e-06, 1.7954e-12, 2.5500e-16, 5.7165e-11, 2.5032e-08, 4.6614e-09,\n",
      "         1.9682e-10, 6.6634e-08, 2.3779e-10, 6.5096e-05, 6.7712e-17, 3.7126e-08,\n",
      "         4.6948e-15, 2.6627e-10, 4.1108e-07, 5.8460e-10, 1.0963e-12, 6.9167e-14,\n",
      "         1.9199e-09, 3.4672e-09, 6.2215e-09, 2.9375e-15, 1.7254e-07, 1.1642e-04,\n",
      "         1.8555e-09, 5.9203e-14, 9.8143e-15, 5.8520e-13, 1.9164e-10, 1.0236e-12,\n",
      "         3.1103e-13, 8.9796e-13, 4.0478e-17, 8.6770e-11]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([1, 70])\n",
      "Ground Truth Shape :  torch.Size([1, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch number :  3\n",
      "Prediction :  tensor([[3.5761e-08, 1.1950e-12, 6.9174e-14, 4.7550e-18, 6.2475e-12, 8.0555e-14,\n",
      "         2.6533e-10, 2.0474e-06, 7.4508e-06, 8.1184e-10, 1.3828e-11, 1.3499e-10,\n",
      "         3.2284e-15, 1.8538e-10, 1.8192e-10, 1.0553e-12, 1.2731e-13, 6.1678e-11,\n",
      "         6.0898e-13, 8.9444e-17, 1.6524e-16, 5.4323e-13, 3.1251e-12, 2.3458e-12,\n",
      "         1.8340e-12, 5.1042e-20, 1.2993e-10, 1.9366e-19, 1.5584e-11, 1.2061e-12,\n",
      "         9.8782e-13, 3.2545e-16, 8.2768e-15, 9.3749e-10, 3.7759e-10, 4.5359e-14,\n",
      "         8.3446e-10, 5.3915e-16, 7.9856e-10, 1.4823e-13, 3.6018e-10, 2.2306e-10,\n",
      "         1.1014e-12, 7.7426e-13, 8.3473e-12, 4.9205e-09, 8.3129e-17, 2.1683e-09,\n",
      "         3.6050e-16, 2.0733e-13, 3.3741e-13, 1.0584e-10, 4.2334e-14, 3.0979e-13,\n",
      "         7.4146e-15, 1.4870e-12, 5.2239e-11, 2.2806e-16, 1.0310e-14, 3.3251e-09,\n",
      "         3.2811e-14, 7.8111e-14, 3.9087e-14, 4.8968e-16, 6.1238e-15, 1.7134e-14,\n",
      "         3.0518e-08, 4.9074e-17, 1.5493e-19, 1.9544e-12],\n",
      "        [5.2444e-12, 7.4182e-18, 1.4206e-16, 9.4592e-21, 2.0623e-17, 9.4343e-13,\n",
      "         1.2283e-17, 3.8647e-13, 7.5169e-08, 1.3828e-14, 1.4903e-13, 7.7902e-19,\n",
      "         3.0670e-15, 2.2232e-18, 8.9257e-10, 1.4362e-11, 3.8785e-10, 1.3287e-07,\n",
      "         1.5328e-14, 4.1685e-18, 9.1121e-16, 7.6595e-13, 2.5761e-15, 1.6607e-14,\n",
      "         3.1628e-14, 1.3976e-18, 1.3297e-14, 9.3586e-13, 1.1241e-12, 8.9815e-11,\n",
      "         1.0413e-14, 1.5097e-15, 7.4883e-16, 4.8023e-17, 1.7988e-14, 1.5846e-14,\n",
      "         3.0201e-09, 1.5096e-16, 1.3825e-17, 6.3141e-14, 6.2981e-13, 6.7288e-13,\n",
      "         5.7320e-17, 1.0543e-06, 1.0390e-11, 7.2764e-15, 5.8761e-21, 2.9195e-08,\n",
      "         7.1632e-17, 2.1059e-10, 8.0647e-11, 1.9662e-13, 2.3602e-14, 4.4195e-17,\n",
      "         6.6020e-17, 1.7390e-16, 8.8924e-13, 5.3650e-18, 2.7494e-12, 5.0319e-05,\n",
      "         1.2087e-17, 1.0764e-16, 5.1308e-17, 1.7777e-21, 7.7808e-14, 4.1932e-15,\n",
      "         1.1793e-10, 7.7736e-14, 1.8741e-15, 5.9859e-17]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([2, 70])\n",
      "Ground Truth Shape :  torch.Size([2, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Prediction :  tensor([[2.8604e-09, 5.8375e-16, 2.4785e-15, 2.7698e-16, 1.3544e-16, 1.3148e-13,\n",
      "         8.5764e-14, 1.1850e-14, 3.6347e-07, 1.9398e-13, 2.5382e-12, 3.1610e-10,\n",
      "         6.2516e-15, 2.2544e-18, 9.7276e-10, 1.2751e-10, 1.4423e-17, 1.4909e-06,\n",
      "         1.4693e-13, 1.8150e-22, 5.3639e-19, 5.8537e-08, 1.1443e-09, 1.5526e-12,\n",
      "         1.0820e-15, 2.6290e-20, 5.1286e-12, 2.0090e-15, 6.6777e-15, 5.4170e-12,\n",
      "         7.9529e-21, 1.9408e-14, 4.1822e-13, 6.9278e-15, 4.7116e-12, 3.3671e-16,\n",
      "         7.8915e-12, 4.1553e-15, 5.5193e-15, 2.3381e-12, 2.1772e-11, 1.6665e-09,\n",
      "         2.0687e-16, 1.1607e-12, 6.6232e-14, 2.3048e-12, 3.0474e-19, 2.6598e-11,\n",
      "         1.6790e-15, 1.5455e-11, 9.1404e-11, 1.1512e-16, 1.9778e-09, 5.7808e-17,\n",
      "         1.2188e-15, 1.7277e-11, 3.8853e-13, 1.3853e-17, 3.0197e-17, 7.3728e-11,\n",
      "         1.0334e-12, 2.3806e-11, 1.3007e-15, 3.8434e-15, 1.6125e-12, 1.4628e-14,\n",
      "         3.4093e-11, 1.2727e-17, 2.0246e-16, 3.4062e-11],\n",
      "        [1.3201e-11, 1.9428e-15, 1.0632e-11, 2.8363e-15, 6.7795e-13, 1.5698e-14,\n",
      "         7.6389e-11, 6.7609e-12, 1.8371e-08, 3.2110e-13, 6.5256e-10, 1.5172e-11,\n",
      "         2.7041e-11, 1.0773e-16, 1.2351e-06, 1.0213e-07, 6.7738e-12, 6.7361e-12,\n",
      "         1.8234e-16, 6.6684e-16, 9.6552e-15, 1.0618e-11, 1.4400e-13, 2.7988e-15,\n",
      "         8.9232e-11, 4.1789e-13, 5.7012e-11, 1.2566e-10, 4.2334e-10, 1.5067e-09,\n",
      "         4.2974e-11, 8.7849e-14, 2.4043e-15, 3.8838e-16, 3.2763e-12, 2.6692e-12,\n",
      "         1.2952e-10, 2.8413e-15, 9.4075e-14, 6.6346e-14, 1.1720e-13, 1.2209e-10,\n",
      "         7.1600e-10, 2.1393e-09, 1.3941e-12, 4.2200e-09, 2.8916e-15, 3.8709e-04,\n",
      "         1.0806e-14, 6.3210e-10, 5.8568e-15, 7.6368e-10, 1.8069e-10, 7.5626e-14,\n",
      "         3.5623e-12, 1.0465e-10, 4.0910e-10, 5.2563e-18, 1.6906e-13, 1.5291e-07,\n",
      "         7.0819e-12, 1.5052e-11, 2.6725e-10, 7.8295e-18, 5.9926e-14, 5.8661e-14,\n",
      "         5.2971e-10, 2.7363e-11, 5.6157e-14, 3.3777e-14]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([2, 70])\n",
      "Ground Truth Shape :  torch.Size([2, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Prediction :  tensor([[1.1020e-19, 3.2288e-14, 6.0698e-17, 4.1793e-20, 2.9157e-20, 5.3611e-23,\n",
      "         6.4418e-17, 1.9465e-21, 5.8199e-15, 1.4906e-14, 3.4985e-14, 1.5479e-17,\n",
      "         4.5051e-20, 9.8790e-17, 7.5468e-20, 6.3863e-13, 1.7523e-11, 4.7499e-16,\n",
      "         7.2044e-18, 2.5701e-22, 8.8185e-18, 5.5669e-22, 1.0838e-14, 2.4968e-17,\n",
      "         2.2999e-16, 2.0485e-17, 9.7305e-22, 2.9269e-23, 1.4762e-15, 1.0387e-19,\n",
      "         2.9052e-15, 1.3412e-21, 2.7884e-23, 5.3433e-15, 3.8730e-13, 2.5627e-19,\n",
      "         4.9041e-21, 1.1149e-18, 4.7923e-17, 3.0204e-19, 5.2957e-12, 3.5344e-13,\n",
      "         1.5656e-17, 6.0927e-12, 5.5459e-22, 3.0769e-09, 1.8320e-22, 6.2092e-13,\n",
      "         4.1437e-21, 3.0570e-16, 8.5306e-19, 5.3752e-19, 1.6581e-20, 6.0773e-18,\n",
      "         6.9731e-17, 6.4995e-10, 9.4894e-14, 4.2730e-23, 5.8495e-14, 1.1210e-10,\n",
      "         2.8680e-24, 1.4215e-16, 1.2265e-15, 2.8736e-17, 9.5361e-17, 4.4785e-21,\n",
      "         5.1085e-17, 1.8389e-22, 5.0976e-27, 1.9901e-20]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Prediction shape :  torch.Size([1, 70])\n",
      "Ground Truth Shape :  torch.Size([1, 70])\n",
      "Ground Truth :  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "loss :  tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    print('Epoch number : ', epoch+1)\n",
    "    train()\n",
    "#     test(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28ad4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.Linear(20, 5) # predict logits for 5 classes\n",
    "# x = torch.randn(1, 20)\n",
    "\n",
    "# y = torch.tensor([[1., 0., 1., 0., 0.]]) # get classA and classC as active\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "# for epoch in range(20):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(x)\n",
    "#     print('output shape : ', output.shape)\n",
    "#     print('output : ',output)\n",
    "#     loss = criterion(output, y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print('Loss: {:.3f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f60de9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data, data.batch)\n",
    "        print(out.shape)\n",
    "        print(out)\n",
    "#         print(out>=0.5)\n",
    "        z = out>=0.5\n",
    "        print(z)\n",
    "        z=z.float()\n",
    "        print('z conversion',z)\n",
    "#         correct +=\n",
    "        print('================')\n",
    "        print(data.y.dtype)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6271a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 70])\n",
      "tensor([[2.0265e-22, 2.9333e-24, 8.6556e-21, 1.2679e-25, 1.5628e-19, 4.0780e-20,\n",
      "         6.2552e-19, 7.3928e-19, 5.4823e-03, 2.1981e-24, 8.1098e-18, 1.9284e-20,\n",
      "         3.5448e-21, 6.9839e-19, 6.1903e-14, 2.6594e-14, 1.5414e-18, 1.4704e-21,\n",
      "         3.1492e-18, 2.8240e-19, 5.6156e-24, 2.2091e-19, 7.9051e-23, 4.2616e-18,\n",
      "         3.0735e-19, 1.4181e-22, 1.7397e-21, 5.3294e-19, 1.6275e-19, 1.0479e-15,\n",
      "         5.3204e-20, 2.1663e-22, 9.6315e-22, 6.5668e-19, 2.2329e-15, 4.1466e-20,\n",
      "         1.6481e-16, 1.5697e-18, 5.9706e-17, 3.6017e-21, 7.8032e-18, 2.7026e-19,\n",
      "         2.1188e-19, 1.1113e-14, 9.7257e-19, 5.0408e-20, 2.0716e-19, 3.5359e-15,\n",
      "         4.5073e-17, 7.4046e-17, 1.4968e-22, 1.5408e-20, 3.1059e-14, 2.3502e-20,\n",
      "         5.8996e-24, 3.6361e-20, 2.1251e-18, 6.3096e-16, 1.1078e-20, 1.3728e-09,\n",
      "         1.1722e-25, 1.1577e-22, 6.2686e-20, 3.3812e-19, 2.9471e-20, 1.3221e-22,\n",
      "         9.1905e-20, 1.4901e-20, 6.1287e-23, 1.7323e-24],\n",
      "        [1.6238e-21, 2.5789e-23, 5.5184e-20, 1.4825e-24, 8.5369e-19, 2.9064e-19,\n",
      "         3.0436e-18, 3.8505e-18, 7.7800e-03, 2.0902e-23, 4.4582e-17, 1.4785e-19,\n",
      "         2.6168e-20, 4.9259e-18, 2.2273e-13, 1.0231e-13, 7.9178e-18, 1.0400e-20,\n",
      "         1.9416e-17, 1.4424e-18, 5.3551e-23, 1.5211e-18, 5.7929e-22, 2.4945e-17,\n",
      "         1.4533e-18, 1.2057e-21, 1.2132e-20, 2.8771e-18, 1.0142e-18, 5.0695e-15,\n",
      "         3.2213e-19, 1.8126e-21, 7.8582e-21, 3.4035e-18, 7.3865e-15, 3.0582e-19,\n",
      "         7.6304e-16, 7.8783e-18, 2.9570e-16, 2.1266e-20, 3.8042e-17, 1.5255e-18,\n",
      "         1.3414e-18, 3.9208e-14, 5.4722e-18, 2.6426e-19, 1.1212e-18, 1.3634e-14,\n",
      "         2.1458e-16, 3.2318e-16, 1.1614e-21, 8.8541e-20, 9.2619e-14, 1.5794e-19,\n",
      "         5.2835e-23, 2.0369e-19, 8.2598e-18, 2.6476e-15, 6.3911e-20, 3.5005e-09,\n",
      "         1.0457e-24, 7.6142e-22, 3.4317e-19, 2.2346e-18, 1.7788e-19, 1.3393e-21,\n",
      "         5.5361e-19, 9.4427e-20, 4.7885e-22, 1.4719e-23]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n",
      "z conversion tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "================\n",
      "torch.float32\n",
      "\n",
      "torch.Size([2, 70])\n",
      "tensor([[3.1293e-23, 4.5026e-25, 1.8395e-21, 1.6037e-26, 2.6822e-20, 8.0340e-21,\n",
      "         1.2962e-19, 1.9033e-19, 3.8446e-03, 3.2836e-25, 2.2516e-18, 4.4748e-21,\n",
      "         8.8711e-22, 2.4014e-19, 2.4206e-14, 8.4738e-15, 4.0894e-19, 3.0477e-22,\n",
      "         9.5901e-19, 7.8573e-20, 9.6041e-25, 6.3816e-20, 1.5744e-23, 1.4250e-18,\n",
      "         5.4551e-20, 2.4457e-23, 3.7869e-22, 1.3850e-19, 3.5821e-20, 3.6788e-16,\n",
      "         9.4974e-21, 4.0757e-23, 2.0518e-22, 1.3803e-19, 7.4203e-16, 1.0889e-20,\n",
      "         4.8397e-17, 3.9865e-19, 1.6830e-17, 6.8019e-22, 2.2057e-18, 5.9940e-20,\n",
      "         5.2355e-20, 3.7353e-15, 2.5481e-19, 7.7120e-21, 3.8724e-20, 1.1063e-15,\n",
      "         1.2673e-17, 1.8529e-17, 2.7143e-23, 2.3041e-21, 1.1053e-14, 5.6906e-21,\n",
      "         9.2524e-25, 6.9955e-21, 3.5776e-19, 2.1329e-16, 2.3037e-21, 6.2656e-10,\n",
      "         1.2871e-26, 1.9119e-23, 1.5831e-20, 9.7259e-20, 5.7813e-21, 2.8081e-23,\n",
      "         2.0045e-20, 2.9093e-21, 9.7924e-24, 2.2931e-25],\n",
      "        [2.0072e-20, 3.4330e-22, 7.1817e-19, 2.6844e-23, 8.4758e-18, 2.4451e-18,\n",
      "         2.2503e-17, 3.1096e-17, 9.5896e-03, 2.7702e-22, 2.7712e-16, 9.9945e-19,\n",
      "         2.4307e-19, 5.1929e-17, 1.3963e-12, 5.5052e-13, 6.4549e-17, 1.2830e-19,\n",
      "         1.8335e-16, 1.9794e-17, 7.8263e-22, 1.2499e-17, 5.2882e-21, 2.0230e-16,\n",
      "         1.1656e-17, 1.3958e-20, 1.2887e-19, 2.0066e-17, 7.6711e-18, 3.1456e-14,\n",
      "         3.2260e-18, 3.0371e-20, 6.7853e-20, 2.0232e-17, 2.7687e-14, 3.0040e-18,\n",
      "         6.5959e-15, 4.8025e-17, 1.9314e-15, 1.3529e-19, 4.3469e-16, 1.0134e-17,\n",
      "         9.7932e-18, 2.3537e-13, 5.9317e-17, 2.2205e-18, 1.2071e-17, 5.9006e-14,\n",
      "         2.2318e-15, 1.9696e-15, 8.6799e-21, 7.8196e-19, 3.9441e-13, 1.5474e-18,\n",
      "         7.4200e-22, 1.8778e-18, 4.6230e-17, 1.4439e-14, 7.0134e-19, 8.6132e-09,\n",
      "         1.4155e-23, 1.1576e-20, 3.4248e-18, 2.6459e-17, 2.0570e-18, 2.2238e-20,\n",
      "         6.1240e-18, 1.0465e-18, 5.9505e-21, 1.7552e-22]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n",
      "z conversion tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "================\n",
      "torch.float32\n",
      "\n",
      "torch.Size([1, 70])\n",
      "tensor([[2.6842e-23, 3.5665e-25, 1.6068e-21, 1.4699e-26, 2.0560e-20, 7.2885e-21,\n",
      "         1.1678e-19, 1.5754e-19, 3.7655e-03, 2.4363e-25, 2.0483e-18, 3.8992e-21,\n",
      "         8.0334e-22, 2.1629e-19, 2.4325e-14, 7.3571e-15, 3.3874e-19, 2.2832e-22,\n",
      "         8.3427e-19, 6.6218e-20, 7.3729e-25, 4.9603e-20, 1.3421e-23, 1.0187e-18,\n",
      "         4.6428e-20, 2.1995e-23, 3.2108e-22, 1.1516e-19, 3.3852e-20, 3.1657e-16,\n",
      "         7.8370e-21, 3.1330e-23, 1.7775e-22, 1.2968e-19, 6.4557e-16, 8.5777e-21,\n",
      "         3.9462e-17, 3.2235e-19, 1.5100e-17, 5.9395e-22, 1.6556e-18, 4.7776e-20,\n",
      "         4.3877e-20, 3.1807e-15, 2.3833e-19, 7.4153e-21, 3.9793e-20, 1.0390e-15,\n",
      "         1.1583e-17, 1.6262e-17, 2.3056e-23, 2.1122e-21, 9.9920e-15, 5.0769e-21,\n",
      "         8.2179e-25, 6.5610e-21, 3.4127e-19, 1.8357e-16, 1.9472e-21, 6.3232e-10,\n",
      "         1.0625e-26, 1.3990e-23, 1.3893e-20, 8.9557e-20, 5.1402e-21, 2.4789e-23,\n",
      "         1.6978e-20, 2.3944e-21, 7.8992e-24, 1.9481e-25]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n",
      "z conversion tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "================\n",
      "torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c766311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
